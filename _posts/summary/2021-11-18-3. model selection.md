

## Model Selection

### 1) Hold-out
![image](https://user-images.githubusercontent.com/45659433/142563379-0be5863f-a426-4751-a026-6b25812f10b6.png)

언더피팅과 오버피팅을 극복하기위해 데이터셋을 A와 같이 Training(70%)과 Test(30%)만 나누는 것이 아니라 B처럼 Training(40%), Validation(30%) 그리고 Test(30%)로 나눈다. 
- Valid : 모델 개선 및 최종선택
- Test : 확정된 모델로 평가, 미래 예측에 대한 최종평가 
	### model error
	![image](https://user-images.githubusercontent.com/45659433/142564184-cca70a7e-9b8e-4973-91bc-45e64b71bcb1.png)
- Training Error :학습데이터에서의 에러
- Generalization Error: 새로운 데이터의 모델에러 (모델 생성에 참여안한 데이터의 오류)
- 이때, Generalization error는 커지고 Training error는 작아지며 사이의 차이가 많이 나게 되면 오버피팅(overfitting)되었다고 판단한다.

### underfitting vs overfitting
|  |단순  | 복잡 |
|--|--|--|
|  |Normal  | **Underfitting** |
|  | **overfitting | Normal  |

### 2) K-fold crossvalidation
### 3) Grid Search
### 4) 모델평가(교차행렬)
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE0MjIwMzk3MTEsLTE4MzgxMzc2NDEsMT
U4MTg3NzAwNiwtNTk4ODc1MDMyXX0=
-->