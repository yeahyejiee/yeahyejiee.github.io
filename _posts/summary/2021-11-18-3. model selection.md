

## Model Selection

### 1) Hold-out
![image](https://user-images.githubusercontent.com/45659433/142563379-0be5863f-a426-4751-a026-6b25812f10b6.png)

언더피팅과 오버피팅을 극복하기위해 데이터셋을 A와 같이 Training(70%)과 Test(30%)만 나누는 것이 아니라 B처럼 Training(40%), Validation(30%) 그리고 Test(30%)로 나눈다. 
- Valid : 모델 개선 및 최종선택
- Test : 확정된 모델로 평가, 미래 예측에 대한 최종평가 
	### model error
	![image](https://user-images.githubusercontent.com/45659433/142564184-cca70a7e-9b8e-4973-91bc-45e64b71bcb1.png)
- Training Error :학습데이터에서의 에러
- Generalization Error: 새로운 데이터의 모델에러 (모델 생성에 참여안한 데이터의 오류)
- 이때, Generalization error는 커지고 Training error는 작아지며 사이의 차이가 많이 나게 되면 오버피팅(overfitting)되었다고 판단한다.

### underfitting vs overfitting
|모델복잡도  |단순  | 복잡 |
|--|--|--|--|
|**모델능력(capacity)**  ||||
| **낮음** |Normal  | **Underfitting** |
| **높음**| **overfitting** | Normal  |

- 과적합(overfitting): 학습데이터 지나치게 적합, 모델 복잡
- 미적합(underfitting): 학습데이터 미진하게 학습, 모델단순
- capacity 
	- 낮은 경우: underfitting
	-  높은 경우: overfitting 

### 2) K-fold crossvalidation
### 3) Grid Search
### 4) 모델평가(교차행렬)
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTQyNDYyMTc3OSwtNDk2MzI5NTM4LC0xOD
M4MTM3NjQxLDE1ODE4NzcwMDYsLTU5ODg3NTAzMl19
-->