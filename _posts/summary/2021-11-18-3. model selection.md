

## Model Selection

### 1) Hold-out
![image](https://user-images.githubusercontent.com/45659433/142563379-0be5863f-a426-4751-a026-6b25812f10b6.png)

언더피팅과 오버피팅을 극복하기위해 데이터셋을 A와 같이 Training(70%)과 Test(30%)만 나누는 것이 아니라 B처럼 Training(40%), Validation(30%) 그리고 Test(30%)로 나눈다. 
- Valid : 모델 개선 및 최종선택
- Test : 확정된 모델로 평가, 미래 예측에 대한 최종평가 
	### model error
	![CSC321 Lecture 9: Generalization](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQE0B6g1OuZ9D3US0qbStFd8xwQSBSWaXidNewlh1afxwp-j_KjVCT1of4FuAUT3TiYvPU&usqp=CAU)
- Training Error :학습데이터에서의 에러
- Generalization Error: 새로운 데이터의 모델에러 (모델 생성에 참여안한 데이터의 오류)

### 2) K-fold crossvalidation
### 3) Grid Search
### 4) 모델평가(교차행렬)
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE5NTEzMTg1ODcsLTE4MzgxMzc2NDEsMT
U4MTg3NzAwNiwtNTk4ODc1MDMyXX0=
-->