

## Model Selection

### 1) Hold-out
![image](https://user-images.githubusercontent.com/45659433/142563379-0be5863f-a426-4751-a026-6b25812f10b6.png)

언더피팅과 오버피팅을 극복하기위해 데이터셋을 A와 같이 Training(70%)과 Test(30%)만 나누는 것이 아니라 B처럼 Training(40%), Validation(30%) 그리고 Test(30%)로 나눈다. 
- Valid : 모델 개선 및 최종선택
- Test : 확정된 모델로 평가, 미래 예측에 대한 최종평가 
	### model error
	![image](https://user-images.githubusercontent.com/45659433/142564184-cca70a7e-9b8e-4973-91bc-45e64b71bcb1.png)
- Training Error :학습데이터에서의 에러
- Generalization Error: 새로운 데이터의 모델에러 (모델 생성에 참여안한 데이터의 오류)
- 이때, Generalization error는 커지고 Training error는 작아지며 사이의 차이가 많이 나게 되면 오버피팅(overfitting)되었다고 판단한다.
- 모델복잡도가 높을 수록  Generalization error과 Training error의 차이는 커진다.

### underfitting vs overfitting
|모델복잡도(capacity)  |  |
|--|--|--|--|
| **낮음** | **underfitting** |
| **높음**| **overfitting** |

- capacity (다양한 함수로 변형될 수 있는 능력)
	-  낮은 경우: underfitting
		-  미적합(underfitting): 학습데이터 미진하게 학습, 모델단순, 데이터 많음
	-  높은 경우: overfitting -> 어떠한 형태로든 변형될 수 있음
		- 과적합(overfitting): 학습데이터 지나치게 적합, 모델 복잡(파라미터수 많음, 가중치 넓은 범위의 값), 학습데이터수가 적음

- 학습데이터 추가확보가 어렵기때문에 모델 복잡도를 조정(차수조정)

### overfitting 방지 (test error를 줄이기 위해 수정)
1) 데이터 수 늘리기
2) feature 수 줄이기
3) dropout 사용
4) regulation
5) batch normalization

### 2) K-fold crossvalidation
### 3) Grid Search
### 4) 모델평가(교차행렬)
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEyNjgyMzc3NjcsNDcyMzkyMzgxLC00OT
YzMjk1MzgsLTE4MzgxMzc2NDEsMTU4MTg3NzAwNiwtNTk4ODc1
MDMyXX0=
-->