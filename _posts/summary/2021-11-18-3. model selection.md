

## Model Selection

### 1) Hold-out
![image](https://user-images.githubusercontent.com/45659433/142563379-0be5863f-a426-4751-a026-6b25812f10b6.png)

언더피팅과 오버피팅을 극복하기위해 데이터셋을 A와 같이 Training(70%)과 Test(30%)만 나누는 것이 아니라 B처럼 Training(40%), Validation(30%) 그리고 Test(30%)로 나눈다. 
- Valid : 모델 개선 및 최종선택
- Test : 확정된 모델로 평가, 미래 예측에 대한 최종평가 


### 2) K-fold crossvalidation

![Cassava Leaf Disease Classification | Kaggle](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F4367831%2Fa7eaffa417f9905be8f0e22af7326ac0%2Fk-fold.jpg?generation=1609935772242624&alt=media)

k-fold crossvalidation은 전체 데이터를 k의 fold를 만들고 각 fold에 train과 test를 나누어 모델을 생성하게 된다. k는 대부분 5나 10을 사용하게되며 k=5일 경우, 총 5번 모델을 생성된다.최종평가는 k개의 모델에서 나오느 test으
### 3) Grid Search
### 4) 모델평가(교차행렬)
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTgyMzUwODIzMiwxMDQ2NDI5MTE4LDQ3Mj
M5MjM4MSwtNDk2MzI5NTM4LC0xODM4MTM3NjQxLDE1ODE4Nzcw
MDYsLTU5ODg3NTAzMl19
-->