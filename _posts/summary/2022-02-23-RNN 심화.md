---

author: Hone Ye ji
categories: 
 - deep learning
 - RNN
tags: 
 - deep learning

use_math: true
toc: true
toc_label: "My Table of Contents"
toc_icon: "cog"
---

# Modern RNN

### deep rnn
$H_t^{(1)}=\phi_1(H_t^{(l-1)}W_{xh}^{(l)}+H_{t-1}^{(l)}W_{hh}^{(l)}+b_n^{(l)})$
$O_t=H_t^{l}W_{nq}+b_q$


## 1) Bidirectional RNNs
- 전체적으로 문장을 봐야 좋다는 관점
- 두개의 독립적인 RNN을 합친 모델
	- 입력 시퀀스는 한 RNN에 대한 정방향, 다른 RNN은 역방향
	- 정확도 낮고 매우 느림
- t : time step , $x \in R^{ n\times d}$: minibatch input

- $\overrightarrow{H_t}=\phi(X_tW_{xh}^{(f)}+\overrightarrow{H}_{t-1})W_{hh}^{(f)}+b_n^{(f)}$
- $\overleftarrow{H_t}=\phi(X_tW_{xh}^{(b)}+\overleftarrow{H}_{t-1})W_{hh}^{(b)}+b_n^{(b)}$
	- concatenate $H_t \in R^{n\times2h}$ : 다음 계층에 입력으로 전달

- $O_t=H_t^{l}W_{hp}+b_q$
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE4MjQ2MjcwNCwyMDk2OTgwMzgxLC0xOT
gyOTkyNzUwLDEyMzQ1MjIzOV19
-->