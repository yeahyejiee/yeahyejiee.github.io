
---
author: Hone Ye ji
categories: 
 - 딥러닝
 
toc: true
toc_label: "My Table of Contents"
toc_icon: "cog"

---

수업들으면서 요점정리했던 것을 기록한다.

# 1. linear regression

딥러닝 초기 문제점
1) 기울기 소실 (vanishing gradient) 
- 기울기소실이란? 학습이 진행되면서 각 파라미터에 대한 가중치의 미분값(경사)가 매우 작아져 0에 가깝게 되는 현상
- 가장 큰 원인은 시그모이드 함수다. 
- 활성화 함수를 시그모이드 함수가 아닌 다양한 활성화 함수를 적용하는 것이 필요하다. 예를들어,  ReLU  max(0,x)를 이용하게 되면 값이 줄어드는 것을 방지할 수 있다. 
- 역전파시키면 gradient값이 input방향으로 진행될 수록 미약해진다. 그러므로 앞쪽 노드들에 대한 weight가 영향을 받지 못한다.
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIwNDk4NjA1OTddfQ==
-->